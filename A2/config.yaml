# Optuna Hyperparameter Tuning Configuration for LightGBM

# Number of trials for the optimization process
n_trials: 3

# LightGBM Hyperparameters search space
# We use a multi-class objective function.
# class_weight='balanced' will be set in the code to handle imbalance.
params:
  n_estimators:
    low: 1582
    high: 1582
  learning_rate:
    low: 0.07712252711113013
    high: 0.07712252711113013
    log: false
  num_leaves:
    low: 67
    high: 67
  max_depth:
    low: 18
    high: 18
  reg_alpha: 
    low: 0.0000012782186865649148
    high: 0.0000012782186865649148
    log: false
  reg_lambda: 
    low: 0.000022415949404234833
    high: 0.000022415949404234833
    log: false
  colsample_bytree:
    low: 0.6072975975499578
    high: 0.6072975975499578
  subsample:
    low: 0.8360710769835231
    high: 0.8360710769835231